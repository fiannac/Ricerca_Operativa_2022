{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from sklearn.datasets import make_blobs\n",
    "from utility import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def neighbors_clustering(sol, points, K):\n",
    "    neighbors = []\n",
    "\n",
    "    q = int(len(sol)/100)\n",
    "\n",
    "    choices = np.arange(len(sol))\n",
    "    orig_val = squared_inner_distance(sol, points, K)\n",
    "    centroids = calc_centroids(sol, points, K)\n",
    "\n",
    "    for i in range(q):\n",
    "        choice = np.random.randint(len(choices))\n",
    "        choices = np.delete(choices, choice)\n",
    "        for k in range(K):\n",
    "            new_sol = sol.copy()\n",
    "            if(k != new_sol[choice]):\n",
    "                new_sol[choice] = k\n",
    "                new_val = orig_val - np.linalg.norm(points[choice]-centroids[sol[choice]]) + np.linalg.norm(points[choice]-centroids[k])\n",
    "                neighbors.append((new_sol,new_val))\n",
    "\n",
    "\n",
    "    choices1 = np.arange(len(sol))\n",
    "    choices2 = np.arange(len(sol))\n",
    "    for i in range(q**2):\n",
    "        choice1 = np.random.randint(len(choices1))\n",
    "        choices1 = np.delete(choices1, choice1)\n",
    "        choice2 = np.random.randint(len(choices2))\n",
    "        choices2 = np.delete(choices2, choice2)\n",
    "\n",
    "        new_sol = sol.copy()\n",
    "        new_sol[choice1], new_sol[choice2] = new_sol[choice2], new_sol[choice1]\n",
    "\n",
    "        new_val = orig_val - np.linalg.norm(points[choice1]-centroids[sol[choice1]]) - np.linalg.norm(points[choice2]-centroids[sol[choice2]]) + np.linalg.norm(points[choice1]-centroids[sol[choice2]]) + np.linalg.norm(points[choice2]-centroids[sol[choice1]])\n",
    "        neighbors.append((new_sol,new_val))\n",
    "        \n",
    "    return neighbors\n",
    "\n",
    "\n",
    "@njit\n",
    "def local_search(base_sol, points, K, verbose = True):\n",
    "    old_sol = base_sol\n",
    "    base_val = squared_inner_distance(old_sol, points, K)\n",
    "    iter = 1\n",
    "    same_sol = 0\n",
    "\n",
    "    while True:\n",
    "        neighbourhood = neighbors_clustering(old_sol, points, K)\n",
    "        best_val = squared_inner_distance(old_sol, points , K)\n",
    "        best_sol = old_sol\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Iteration number:\", iter, \"Valore percentuale:\", best_val/base_val*100, \"%\")\n",
    "\n",
    "        for sol,val in neighbourhood:\n",
    "            if(val < best_val):\n",
    "                best_val = val\n",
    "                best_sol = sol\n",
    "        \n",
    "        if(best_sol is old_sol):\n",
    "            same_sol = same_sol + 1\n",
    "            if(same_sol == 100):\n",
    "                break\n",
    "        else:\n",
    "            same_sol = 0\n",
    "            old_sol = best_sol\n",
    "\n",
    "        iter = iter+1\n",
    "    return old_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "N = 1000\n",
    "\n",
    "points, centroids = make_blobs(n_samples=N, centers=K, n_features=2, random_state=np.random.randint(10))\n",
    "\n",
    "sol = np.random.randint(K, size = N)\n",
    "sol = local_search(sol, points, K)\n",
    "\n",
    "print(\"Il valore di f.obj ottenuta Ã¨: {:.5E}\".format(squared_inner_distance(sol, points, K)))\n",
    "\n",
    "printR2sol(points, sol, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = [500,1000,1000,1000,1000,1000,1500,1500,2000,3000,5000,10000]\n",
    "n_clusters = [5,2,4,5,6,7,5,10,5,5,5,10]\n",
    "dim_points = [32,32,32,32,20,20,18,18,18,16,16,16]\n",
    "\n",
    "\n",
    "vals = []\n",
    "\n",
    "for test in tqdm(range(1,13)):\n",
    "    points = load_points(f'C:/Users/franc/Documents/GitHub/Ricerca_Operativa_2022/Ricerca_Operativa_2022/benchmark/benchmark{test}.txt')\n",
    "    N = len(points)\n",
    "    K = n_clusters[test-1]\n",
    "    sol = np.random.randint(K, size = N) #soluzione iniziale\n",
    "    sol = local_search(sol, points, K, False)\n",
    "    val = squared_inner_distance(sol, points, K)\n",
    "    vals.append(val)\n",
    "    print(val)\n",
    "print(vals)\n",
    "with open(\"risultatiLS.txt\", 'w') as file:\n",
    "    file.write(\"Local search:\\n\")\n",
    "    file.write(str(vals))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e03b612d84ba21ce95ed447e81b3062e1eb99b56c6d885cdab4aaa12f1b8e240"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
